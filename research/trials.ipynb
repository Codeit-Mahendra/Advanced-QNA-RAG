{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "f0720240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "7517dc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\'"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "657a30c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\'"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb5535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "436b7580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_files(data):\n",
    "\n",
    "    loader = DirectoryLoader(  #Created to load all PDF files from a directory\n",
    "        data,\n",
    "        glob = \"*.pdf\",\n",
    "        loader_cls=PyPDFLoader,\n",
    "    )\n",
    "\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "extracted_data = load_pdf_files(\"D:\\Advanced-QNA-RAG\\data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "c672af10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'D:\\\\Advanced-QNA-RAG\\\\data\\\\Three Thousand Stitches by Sudha Murthy.pdf', 'page': 33}, page_content='others\\tsay\\tit\\tcame\\tfrom\\tMexico.\\tAccording\\tto\\ta\\ttheory,\\tblack\\tpepper\\twas\\tthe\\ningredient\\ttraditionally\\tused\\tin\\tIndia\\tto\\tmake\\tour\\tfood\\thot\\tand\\tspicy.\\tSome\\nscholars\\tbelieve\\tthat\\tthe\\tsole\\tgoal\\tof\\tthe\\tEast\\tIndia\\tCompany\\twas\\tto\\tacquire\\ta\\nmonopoly\\tover\\tIndia’s\\tpepper\\ttrade,\\n\\twhich\\tlater\\tended\\tin\\tIndia’s\\tcolonization.\\nBut\\twhen\\twe\\tbegan\\tusing\\tchillies,\\twe\\tfound\\tthat\\tit\\ttasted\\tbetter\\tthan\\tblack\\npepper.\\tTo\\tgive\\tyou\\tan\\texample,\\twe\\trefer\\tto\\tblack\\tpepper\\tas\\t\\nkalu\\tmenasu\\n\\tin\\nKannada.\\tWe\\tgave\\ta\\tsimilar\\tname\\tto\\tthe\\tchilli\\tand\\tcalled\\tit\\t\\nmenasin\\tkai\\n.\\tIn\\nHindi,\\tit\\tis\\tfrequently\\treferred\\tto\\tas\\t\\nmirchi\\n.\\tIn\\tthe\\twar\\tbetween\\tblack\\tpepper\\tand\\nchilli,\\tthe\\tformer\\tlost\\tand\\tchilli\\testablished\\n\\titself\\tas\\tthe\\tnew\\tprince\\tand\\tcontinues\\nto\\trule\\tthe\\tIndian\\tfood\\tindustry\\teven\\ttoday.\\tnorth\\tKarnataka\\tis\\tfamous\\tfor\\tits\\tred\\nchillies\\tnow.’\\n‘That\\tmuch\\tI\\tdo\\tknow,\\tUncle!’\\tI\\tclosed\\tmy\\teyes\\tand\\thad\\ta\\tvision\\tof\\tmy\\nyounger\\tdays.\\t‘I\\tremember\\tseeing\\tacres\\tand\\tacres\\tof\\tred\\tchilli\\tplants\\tduring\\tmy\\nchildhood.\\tThe\\tharvest\\tused\\tto\\ttake\\tplace\\tduring\\tthe\\tDiwali\\tseason.\\tI\\tremember\\nthat\\tthe\\tBadgi\\tdistrict\\twas\\tdedicated\\n\\tto\\tthe\\tsale\\tof\\tchillies.\\tI\\thad\\tgone\\twith\\tmy\\nuncle\\tone\\tday\\tand\\twas\\tamazed\\tby\\tthe\\tmountains\\tof\\tred\\tchillies\\tI\\tsaw\\tthere.’\\n‘Oh\\tyes,\\tyou\\tare\\tright!\\tThose\\tred\\tchillies\\tare\\tbright\\tred\\tin\\tcolour\\tbut\\tthey\\naren’t\\treally\\thot\\tor\\tspicy.\\tOn\\tthe\\tcontrary,\\tchillies\\tthat\\tgrow\\tin\\tthe\\tstate\\tof\\nAndhra\\tPradesh\\tin\\tthe\\tarea\\tof\\tGuntur\\tare\\textremely\\tspicy.\\tThey\\tare\\ta\\tlittle\\nrounded\\tin\\tshape,\\tnot\\tas\\tdeep\\tred\\tin\\tcolour\\n\\tand\\tare\\tcalled\\tGuntur\\tchillies.\\tA\\ngood\\tcook\\tuses\\ta\\tcombination\\tof\\tdifferent\\tkinds\\tof\\tchillies\\tto\\tmake\\tthe\\tdish\\ndelicious\\tand\\tattractive.\\tNow\\tthat’s\\twhat\\tI\\tcall\\tindigenous.’\\n‘There\\twere\\talso\\ttwo\\tother\\tkinds\\tof\\tchillies\\tin\\tour\\tfarm—one\\twas\\ta\\tchilli\\ncalled\\tGandhar\\tor\\tRavana\\tchilli\\tthat\\tgrows\\tupside\\tdown\\tand\\tthe\\tother\\tone,\\tof\\ncourse,\\twas\\tcapsicum.’\\nUncle\\tnodded.\\t‘Capsicum\\tin\\tIndia\\tis\\tnothing\\tbut\\n\\tgreen\\tor\\tred\\tbell\\tpeppers\\tin\\nthe\\tWest.\\tBut\\tif\\tyou\\teat\\tone\\ttiny\\tRavana\\tchilli,\\tyou\\twill\\thave\\tto\\tsit\\tin\\tthe\\nbathroom\\twith\\tyour\\tbackside\\tin\\tpain\\tand\\tdrink\\tmany\\tbottles\\tof\\twater\\tfor\\ta\\tlong,\\nlong\\ttime!\\tOr\\tyou\\twill\\thave\\tto\\teat\\tfive\\thundred\\tgrams\\tof\\tcandies,\\tsweets\\tor\\nchocolates.’\\nWe\\tboth\\tlaughed.\\nHearing\\tthe\\tlaughter,\\tRekha’s\\tmother\\tcame\\tand\\tjoined\\tus.\\t‘Are\\tyou\\tfolks\\njoking\\tabout\\ttoday’s\\tmenu?\\tI’m\\n\\tsorry\\tthat\\tthere\\twasn’t\\tmuch\\tvariety.\\tWhen\\tI\\nheard\\tthat\\tyou\\twere\\tcoming\\tfor\\tlunch,\\tI\\ttold\\tUncle\\tto\\tinform\\tyou\\tthat\\ttoday’s')]"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data[33:34]  #Displaying first two loaded documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "b42707b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(extracted_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "66d7ffc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', None),\n",
       " ('metadata',\n",
       "  {'source': 'D:\\\\Advanced-QNA-RAG\\\\data\\\\Three Thousand Stitches by Sudha Murthy.pdf',\n",
       "   'page': 2}),\n",
       " ('page_content',\n",
       "  'SUDHA\\tMURTY\\n\\t\\nTHREE\\tTHOUSAND\\tSTITCHES\\nOrdinary\\tPeople,\\tExtraordinary\\tLives\\nPENGUIN\\tBOOKS'),\n",
       " ('type', 'Document')]"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [i for i in extracted_data[34].metadata.items()]  #Displaying metadata of first document\n",
    "\n",
    "[i for i in extracted_data[2]]  #Displaying metadata of first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "8906295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data = [\n",
    "#     ('id', None),\n",
    "#     ('metadata',\n",
    "#      {'producer': 'calibre 3.42.0 [https://calibre-ebook.com]',\n",
    "#       'creator': 'calibre 3.42.0 [https://calibre-ebook.com]',\n",
    "#       'creationdate': '2019-07-12T08:02:34+00:00',\n",
    "#       'author': 'Sudha Murty',\n",
    "#       'title': 'Three Thousand Stitches - PDFDrive.com',\n",
    "#       'source': 'data\\\\Three Thousand Stitches by Sudha Murthy.pdf',\n",
    "#       'total_pages': 128,\n",
    "#       'page': 3,\n",
    "#       'page_label': '4'}),\n",
    "#     ('page_content', '...'),\n",
    "#     ('type', 'Document')\n",
    "# ]\n",
    "\n",
    "# # Extract producer\n",
    "# producer = next((value['producer'] for key, value in data if key == 'metadata'), None)\n",
    "# print(producer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ff7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "def filter_to_minimal_docs(docs: List[Document]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Given a list of Document objects, return a new list of Document objects\n",
    "    containing only 'source' in metadata and the original page_content.\n",
    "    \"\"\"\n",
    "    minimal_docs: List[Document] = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        src = doc.metadata.get(\"source\")\n",
    "        minimal_docs.append(\n",
    "            Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={\"source\": src}\n",
    "            )\n",
    "        )\n",
    "    return minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "5498ca4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'D:\\\\Advanced-QNA-RAG\\\\data\\\\Three Thousand Stitches by Sudha Murthy.pdf'}, page_content='')"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimal_docs = filter_to_minimal_docs(extracted_data)\n",
    "minimal_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "e0a686aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the documents into smaller chunks\n",
    "def text_split(minimal_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(  # defined to split text into smaller chunks\n",
    "        chunk_size=300,\n",
    "        chunk_overlap=50,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \"; \", \", \", \" \"],\n",
    "        length_function=len\n",
    "    )\n",
    "    texts_chunk = text_splitter.split_documents(minimal_docs)\n",
    "    return texts_chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "067dac73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 1044\n"
     ]
    }
   ],
   "source": [
    "texts_chunk = text_split(minimal_docs)\n",
    "print(f\"Number of chunks: {len(texts_chunk)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7acf05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import unicodedata\n",
    "\n",
    "# def clean_text(texts_chunk):\n",
    "#     text = unicodedata.normalize(\"NFKD\", texts_chunk.page_content)\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(r\"\\s+\", \" \", text)  # Collapse whitespace\n",
    "#     texts_chunk = re.sub(r\"[^\\w\\s.,:;!?()-]\", \"\", text)  # Remove junk characters\n",
    "#     return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "2b0bf879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 1044\n"
     ]
    }
   ],
   "source": [
    "texts_chunk = text_split(minimal_docs)\n",
    "print(f\"Number of chunks: {len(texts_chunk)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "7cc1a7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'D:\\\\Advanced-QNA-RAG\\\\data\\\\Three Thousand Stitches by Sudha Murthy.pdf'}, page_content='SUDHA\\tMURTY\\n\\t\\nTHREE\\tTHOUSAND\\tSTITCHES\\nOrdinary\\tPeople,\\tExtraordinary\\tLives\\nPENGUIN\\tBOOKS')"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_chunk[0]  #Displaying first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb115e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def download_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "# Test it\n",
    "embeddings = download_embeddings()\n",
    "print(\"Embeddings loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "e4250187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "2722a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API keys\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")  # ✅ This line was missing\n",
    "\n",
    "# Set them in environment (optional, if needed by other libraries)\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "8930c364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.control.pinecone.Pinecone at 0x21d25ff58d0>"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone import Pinecone \n",
    "pinecone_api_key = PINECONE_API_KEY\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4b2cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'chatbot' already exists.\n",
      "Connected to index: chatbot\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "index_name = \"advanced-qna-rag\"\n",
    "\n",
    "# Check if index exists by listing all indexes\n",
    "existing_indexes = pc.list_indexes().names()\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    print(f\"Creating index: {index_name}\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,  # Dimension of the embeddings\n",
    "        metric=\"cosine\",  # Cosine similarity\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    print(f\"Index '{index_name}' created successfully!\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists.\")\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "print(f\"Connected to index: {index_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49c6c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "8d6c9dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PineconeVectorStore imported successfully!\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "print(\"PineconeVectorStore imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "558b90bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created successfully!\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Assuming texts_chunk and embedding are defined from earlier cells\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=texts_chunk,\n",
    "    embedding=embeddings,  # Note: Your notebook uses 'embeddings' in cell 31, which should be 'embedding'\n",
    "    index_name=index_name\n",
    ")\n",
    "print(\"Vector store created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "7408783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "5ecaf14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"Who is sudha murthy?\")\n",
    "# retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "0139b816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: groq/compound\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "\n",
    "# Update your model to a working one\n",
    "chatModel = ChatGroq(\n",
    "    model=\"groq/compound\",  # Working model\n",
    "    # model=\"openai/gpt-oss-120b\",  # Working model,\n",
    "    temperature=0.2,\n",
    "    groq_api_key=os.environ.get(\"GROQ_API_KEY\")\n",
    ")\n",
    "\n",
    "print(f\"Using model: {chatModel.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "c94a8016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1356f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chat model has two input system & User prompt\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are the best assistant for answering questions based on the provided context. \"\n",
    "    \"Use the context below to answer accurately and factually. \"\n",
    "    \"If you don't know the answer, say clearly You don't know. \"\n",
    "    \"Limit your response to two sentences.\\n\\n{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56977549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Chain\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(chatModel, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "3dd7662f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The narrator was repeatedly told that women didn’t belong in engineering—she was expected to study medicine or science with other female students, and her presence in an engineering program was dismissed as “like expecting pigs to fly.” Her classmates expressed that bias through constant sarcasm, pranks, pitying remarks (e.g., comparing her to Goddess Parvati and questioning why she chose engineering) and demeaning comments that questioned her motives and ability.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What specific academic challenges and forms of harassment did the narrator face from her classmates in engineering college??\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "9c7e3d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "College taught her resilience, flexibility, and collaborative skills—psychological coping tools that let her transform fear into confidence—while her academic success reinforced her self‑identity as a capable engineer; together, these strategies enabled her to confront hostility, build supportive relationships, and ultimately thrive despite the hostile environment.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"How did the narrator's psychological coping strategies and academic performance interact to help her overcome the hostile environment??\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "91e5b9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The narrator’s transformation—from an “alien” outsider to a respected peer—demonstrates that demonstrable competence and relentless persistence can overturn gendered expectations, earning admiration and friendship even in hostile environments. By consistently proving skill and resilience, the narrator dismantles stereotypes, showing that sustained excellence is a powerful catalyst for breaking gender barriers.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\":\"What does the narrator's journey from being an alien to gaining respect and making friends reveal about the transformative power of competence and persistence in breaking gender barriers?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "54ba425c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The passage illustrates that individual excellence—whether it is the narrator’s own academic and professional achievements, his father’s unusually liberal support for his daughters’ education, or the doctor‑teacher’s reputation for caring for women—acts as a catalyst that both exposes and begins to erode entrenched gender stereotypes in male‑dominated arenas. At the same time, the narrative makes clear that personal success alone cannot overturn systemic bias; it must be reinforced by concrete institutional changes (such as the provision of women’s toilets on campus), collective advocacy, and supportive networks that validate and amplify women’s aspirations, thereby turning isolated instances of excellence into a broader, sustainable shift in cultural expectations and structural opportunities.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"Considering both the societal context described and the narrator's personal transformation, what does this passage suggest about the relationship between individual excellence and systemic change in challenging gender stereotypes in male-dominated fields?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674bc3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://chat.deepseek.com/share/8fp97r8nzc6i11es4k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4828a51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\mahen\\miniconda3\\envs\\gen_ai\\lib\\site-packages (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install python-dotenv\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GEN_AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
